{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setAppName('PracticeRDD')\n",
    "sc = SparkContext(conf=conf).getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "n = '\\n'\n",
    "sample_weather_file = '/Users/juliushernandez/Documents/GitHub/__dc_pipelines__/evergreen/evergreen_custom_payloads_sample_data/payload.com.apple.hai.Evergreen.Weather.json'\n",
    "nums_file = 'data/nums.txt'\n",
    "txt_file = 'data/text.txt'\n",
    "mango_txt = 'data/mango.txt'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Practice RDD Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "currentConditions âœ…\n",
    "eventTime âœ…\n",
    "eventTimezone âœ…\n",
    "hourlyForecast âœ…\n",
    "payloadVersion âœ…\n",
    "sampleID âœ…\n",
    "\"\"\"\n",
    "def txt_split(s):\n",
    "    s_list = s.split(' ')\n",
    "    l2 = []\n",
    "    for v in s_list:\n",
    "        l2.append(int(v) * 2)\n",
    "    return l2\n",
    "\n",
    "def letter_count(s):\n",
    "    words = s.split(' ')\n",
    "    word_lengths = []\n",
    "    for word in words:\n",
    "        word_lengths.append(len(word))\n",
    "    return word_lengths\n",
    "\n",
    "def practice1():\n",
    "    rdd_text = sc.textFile(nums_file)\n",
    "    l_text = rdd_text.collect()\n",
    "    print(l_text)\n",
    "\n",
    "    rdd_text2 = rdd_text.map(txt_split)\n",
    "    l_text2 = rdd_text2.collect()\n",
    "    print(l_text2)\n",
    "\n",
    "    rdd_words = sc.textFile(txt_file)\n",
    "    print('\\n--> getting lengths of each word for\\n', rdd_words.collect(), '\\n')\n",
    "    l_words = rdd_words.map(letter_count)\n",
    "    l_words = l_words.collect()\n",
    "    print('\\nlengths =\\n', l_words)\n",
    "\n",
    "def practice_map():\n",
    "    rdd_words = sc.textFile(txt_file)\n",
    "\n",
    "    rdd_pipe_words_map = rdd_words.map(lambda s: [len(s) for s in s.split(' ')])\n",
    "    print('\\n_> length of all the words\\n', rdd_pipe_words_map.collect())\n",
    "\n",
    "    rdd_pipe_words_flat_map = rdd_words.flatMap(lambda s: s.split(' '))\n",
    "    rdd_pipe_words_flat_map_len = rdd_words.flatMap(lambda s: [len(s) for s in s.split(' ')])\n",
    "    print('\\n_> Flat Map version\\n', rdd_pipe_words_flat_map.collect(),\n",
    "          '\\n', rdd_pipe_words_flat_map_len.collect())\n",
    "\n",
    "def practice_filter():\n",
    "    rdd_mango = sc.textFile(mango_txt)\n",
    "    def filter_ac(s):\n",
    "        if s[0] in ['a', 'c']:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    r_p_mango = rdd_mango.filter(filter_ac)\n",
    "    print('\\n_> filtered result:\\n', r_p_mango.collect())\n",
    "\n",
    "def practice_distinct():\n",
    "    rdd_nums = sc.textFile(nums_file)\n",
    "    r_p_nums = rdd_nums.flatMap(lambda s: s.split(' '))\n",
    "    r_p_nums_distinct = r_p_nums.distinct()\n",
    "    # chain\n",
    "    r_p_nums_distinct_chain = rdd_nums.flatMap(lambda s: s.split(' ')).distinct().collect()\n",
    "    print('_> flat map:\\n', r_p_nums.collect(),\n",
    "          n, r_p_nums_distinct.collect(),\n",
    "          n, r_p_nums_distinct_chain)\n",
    "\n",
    "def groupbykey_prac():\n",
    "    rdd_mango = sc.textFile(mango_txt)\n",
    "    r_p_mango = rdd_mango.flatMap(lambda s: s.split(' ')).map(lambda s: (s, len(s)))\n",
    "    print(r_p_mango.groupByKey().mapValues(list).collect())\n",
    "\n",
    "def reducebykey_prac():\n",
    "    rdd_nums = sc.textFile(nums_file)\n",
    "    r_p_map = rdd_nums.flatMap(lambda s: s.split(' ')).map(lambda s: (s, 1))\n",
    "    r_p_map.collect()\n",
    "    r_p_reduce = r_p_map.reduceByKey(lambda a, b: a + b)\n",
    "    print(r_p_reduce.collect())\n",
    "\n",
    "def word_count_quiz():\n",
    "    rdd_mango = sc.textFile(mango_txt)\n",
    "    r_p_mango = rdd_mango.flatMap(lambda s: s.split(' ')).map(lambda s: (s, 1))\n",
    "    r_p_mango_reduce = r_p_mango.reduceByKey(lambda a, b: a + b)\n",
    "    print( r_p_mango_reduce.collect() )\n",
    "\n",
    "\n",
    "# end of cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Main Practice Cell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "['this mango company animal',\n 'cat dog ant mic laptop mango',\n 'chair switch mobile am charger cover',\n 'amanda mango mango any alarm ant']"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_mango = sc.textFile(mango_txt)\n",
    "rdd_mango.collect()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('\\n\\n\\t\\t _> Spark Job complete ðŸ¤— âœ… \\n\\n')"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
